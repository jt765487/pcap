# PCAP Uploader Service

## Overview

This project provides a robust background service (`pcap_uploader.py`) designed to process `.pcap` files generated by an external application (like the included `test_generator.py`) and upload them to a remote endpoint, typically an Apache NiFi instance.

The script runs continuously, monitoring a source directory and processing files based on records found in a corresponding CSV manifest file. It ensures reliable file handling and uploads through careful state management, error handling, and retry mechanisms.

**Core Responsibilities:**

1.  **CSV Processing:** Monitors a CSV file (e.g., `SHA256-HASH.csv`) for new records. Each record is expected to contain `<epoch time>,<full file path>,<SHA256-HASH result>`. It uses offset tracking and file metadata (inode/size) to efficiently process only new records and handle CSV file changes (appends, truncations, replacements).
2.  **File Staging:** Moves validated files listed in the CSV from a `source_dir` to a `work_dir` for processing.
3.  **Startup File Recovery:** Scans the `source_dir` **once at startup** for any `.pcap` files potentially missed by the CSV processing (e.g., orphaned files from previous runs) and moves them directly to the `work_dir`. Normal processing relies on CSV entries after startup.
4.  **Reliable Upload:** Attempts to send files from the `work_dir` via HTTP POST to a configured `remote_host_url` (e.g., NiFi ListenHTTP processor). Implements indefinite retries with exponential backoff for transient network errors and retryable server status codes.
5.  **Error Handling:** Moves files that fail permanently during upload to a `dead_letter_dir` and files that fail critical move operations to a `failed_move_dir`.
6.  **Efficient Monitoring:** Uses `watchdog` to monitor the CSV directory for changes in real-time, triggering processing promptly.
7.  **Graceful Shutdown:** Handles `SIGTERM` and `SIGINT` signals (common in service management) to shut down cleanly, finishing in-progress tasks where possible and stopping monitors.
8.  **Configuration:** All behavior (directories, endpoint, timings, retries, logging) is controlled via a `config.ini` file.

## Features

*   Stateful CSV processing resilient to appends, truncations, and replacements.
*   Atomic file movement across stages (`source` -> `work` -> `done`/`failed`).
*   Requires all managed directories reside on the **same filesystem**.
*   Robust HTTP POST uploads with exponential backoff and indefinite retries for network issues.
*   Differentiated handling for permanent upload errors (dead-lettering).
*   Recovery mechanism for orphaned files in the source directory.
*   Event-driven CSV monitoring via `watchdog`.
*   Graceful shutdown handling for service integration.
*   Fully configurable via `config.ini`.
*   Includes test data generator and endpoint simulator utilities.

## Prerequisites

*   Python 3.6+
*   `pip` (Python package installer)
*   Access to the filesystem locations specified in `config.ini`.
*   Network connectivity to the target endpoint specified in `config.ini`.

## Setup & Installation

1.  **Get the Code:** Clone the repository or download the source code files.
    ```bash
    # Example using git
    # git clone <your-repository-url>
    # cd <repository-directory>
    ```

2.  **Create a Virtual Environment (Recommended):**
    Using a virtual environment prevents conflicts with other Python projects.
    ```bash
    python -m venv venv
    source venv/bin/activate  # Only works on Linux
    ```

3.  **Install Dependencies:**
    There are two requirements files:
    *   **For running only the main uploader service (`pcap_uploader.py`):**
        ```bash
        pip install -r requirements.txt
        ```
        *(Installs `requests`, `watchdog`)*

    *   **For development (running tests, linters, simulators):**
        ```bash
        pip install -r requirements-dev.txt
        ```
        *(Installs core requirements plus `flask`)*

## Configuration (`config.ini`)

The service requires a configuration file named `config.ini` located in the same directory as `pcap_uploader.py`. Alternatively, the path can be specified via the `PCAPUPLOADER_CONFIG` environment variable.

The file uses standard INI format. Edit the values below as needed for your environment.

```ini
# ----------------------------------------------------------
# Configuration File for the PCAP Uploader Service
# ----------------------------------------------------------

[Directories]
# These are the folders the service will use.
# IMPORTANT: All these directories MUST be on the same filesystem/mount point
# for atomic file moves. Ensure they exist and the service has permission
# to read/write.

# Source directory where the external application writes .pcap files
source_dir = /var/tmp/MOVE/src

# Working directory for files being processed or awaiting upload
work_dir = /var/tmp/MOVE/work

# Directory containing the CSV manifest file specified in [Files]
csv_dir = /var/tmp/MOVE/csv

# Directory for successfully uploaded files
done_dir = /var/tmp/MOVE/done

# Directory for files that failed critical move operations
# (e.g., couldn't be moved to work_dir or done_dir after retries)
failed_move_dir = /var/tmp/MOVE/failed_move

# Directory for files that failed upload permanently
# (e.g., server rejected them, non-retryable errors)
dead_letter_dir = /var/tmp/MOVE/dead_letter

[Files]
# Name of the CSV manifest file located in 'csv_dir'
# Format expected: <epoch time>,<full file path>,<SHA256-HASH result>
csv_filename = SHA256-HASH.csv

[Network]
# Settings for connecting to the remote server (e.g., NiFi ListenHTTP).

# Full URL of the remote endpoint for uploading PCAP files
# Example: http://your-nifi-node:8989/contentListener
remote_host_url = http://192.168.0.180:8989/pcap

# How long (in seconds) to wait for the server to respond during an upload attempt
request_timeout = 20

# SSL Certificate Verification for HTTPS endpoints.
# - Set 'true' if using HTTPS AND the server has a valid, trusted SSL certificate.
# - Set 'false' to disable certificate checking (e.g., for self-signed certs).
# WARNING: Setting to 'false' is insecure and MUST NOT be used in production
#          environments unless you fully understand the risks.
#          Production endpoints should use HTTPS with valid certificates.
verify_ssl = false

[Timing]
# Controls how often tasks run and how long to wait for retries.

# How often (in seconds) to scan the work_dir for files pending upload
work_dir_poll_interval = 5

# Initial delay (in seconds) before retrying a failed network connection/upload
initial_backoff = 1

# Maximum delay (in seconds) between network retries (prevents excessively long waits)
max_backoff = 60

# Delay (in seconds) between retrying a failed file move operation
move_retry_delay = 1

[Retries]
# Controls how many times certain operations are attempted.

# Maximum number of attempts for critical file moves (e.g., src->work, work->done)
move_max_retries = 3

# Maximum attempts to generate a unique filename if a file with the same name
# already exists in the destination directory during a move.
max_collision_attempts = 1000

[Logging]
# Controls the level of detail in the service logs (stdout and syslog if available).
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
#   INFO: Shows normal operations (recommended default).
#   DEBUG: Very detailed, for troubleshooting.
log_level = INFO